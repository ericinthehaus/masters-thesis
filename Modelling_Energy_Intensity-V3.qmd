---
title: "Modelling"
author: "Eric"
abstract-title: "Main idea"
abstract: |
 The most densely populated areas have the worst energy intensity. Wind energy generated has a positive relationship with energy intensity, meaning more wind energy is related to worse energy intensity. Only a couple months have a siginificant affect on predicting energy intensity. And different months do not have significant affect mean intensity overall. Only when combined with CCAA does it show an effect.
editor: source
editor_options: 
  chunk_output_type: inline
  toc: true
format: 
  pdf:
    toc: true
    keep-tex: true
    toc-depth: 3
    embed-resources: true
    documentclass: report
    geometry:
      - top=30mm
      - left=20mm
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.width = 7, fig.height = 4)
knitr::knit_hooks$set(inline = function(x) {format(x, digits = 4, big.mark = ",")}) 
library(tidyverse)

load(".RData")
#rm(list = ls())
#load("./for_modelling.RData")

new_theme <- theme_classic()
theme_set(new_theme)
theme_update(
  plot.background = element_rect(fill = "gray90"),
  plot.title.position = "plot", 
)
```

\newpage 

**Hypothesis 1:** \
An increase in wind energy generated is associated with a decrease in energy intensity, for each CCAA in 2023.

**Method:** Sectional modelling 

## Data wrangling 

```{r agg-date, echo=FALSE}
agg_data <- PIVOT_data_pop_pib_land_energy |> 
#  select(-c(value.x_NA, percentage_NA)) |> 
  mutate(
    datetime = lubridate::dhours(2) + datetime, 
    date = as.Date(datetime),
    month = factor(month),
    energy_int = 1000*value.y/PIB,
    logPopden = log10(pop.density + 1),
    logEolica = log10(value.x_Eólica + 1),
    logGenTotal = log10(`value.x_Generación total`)
  ) |>  
  left_join(
    survey, by = "CCAAnombre"
  ) |> 
  mutate(
        logPop = log10(pop)
  ) |> 
  left_join(
    mes_clima, by = join_by("CCAAnombre", "month" )
  ) |> 
  mutate(
    prec = prec/1000 ## convert from "mm" to "meters"
  ) |> 
  rename(
    land_area = Superf,
    GDP = PIB,
    consumption = value.y,
    GenTotal = `value.x_Generación total`,
    Eolica = value.x_Eólica,
    survey_respondents = total.y,
    issues_p = response_p
  )

agg_data2022 <- agg_data |> 
  filter(
    lubridate::year(date) == 2022 
  ) 
```

## Correlations 
The Pearson's correlation between wind energy generated (MWh) and energy intensity (MWh/€) is `r cor(agg_data2022$Eolica, agg_data2022$energy_int)`. But the correlation changes to `r cor(agg_data2022$logEolica, agg_data2022$energy_int)` when you use the logged wind generation. That suggests that the relationship is log-linear. In other words, a multiplicative change to wind energy is associated with a linear unit of change in energy intensity. Since the correlation is positive, we can say that a multiplicative increase in wind energy is associated with a linear increase in energy intensity. 

```{r, fig.width=7, fig.height=6}
ggcorrplot::ggcorrplot(cor(agg_data2022[, c(2,4,7,8,11,14:15,17,20:24,26:31,34:37)]),
                        type = "lower", hc.order = T, 
                       ggtheme = theme_gray()
                       )
```


```{r cor-plot, fig.height=9, fig.width= 7, fig.cap="Correlation Matrix"}


DataExplorer::plot_correlation(agg_data2022[, c(2,4,7,8,11,14:15,17,20:24,26:31,34:37)], 
                               title = "Correlation matrix of all variables", 
                               geom_text_args = list(size = 2), 
                               ggtheme = theme_classic()
                               )
```
## Linear Models 

`lm_basic` \
First, I ran a simple linear regression with `logEolica` and `percentage_Eólica` as the only predictor variables. The results suggest that wind energy generation has a relationship with energy intensity. The logged output of wind energy, `logEolica`, is strongly related to energy intensity. The percentage of total electricity generated in a CCAA, `percentage_Eólica`, is not as strongly related. For two CCAA with the same amount of wind energy generated, the one with a higher percentage is very likely to have a lower energy intensity. Furthermore, the Adjusted R^2^ is almost 50%, which is good. 

`for_tune` \
Next, I ran a forward selection regression, with 10 predictors. I did not include month or CCAA. The results showed that four predictors is good, because after that the RMSE increased with five or six variables. You can see that the best model with six predictors were: `logEolica`, `logPop`, `mas`, `logGenTotal`, `prec`, and `tmin`. The best model with seven predictors included the same plus `ns`. Although the RMSE and R^2^ keep increasing as you add more predictors, the first jump is from six to seven. Before that, adding a variable to the model does not make the overall model's variation metrics improve significantly. And after seven variables, I am afraid that there would be very much collinearity. 

I was hesitant to include `ns` because it has a clear outlier due to low sample size. This variable represents the percent of respondents who answered "I don't know" to the survey question about environmental degration in 10 years. The problem is that **Ceuta** had a very low sample size and then had a much higher proportion of "I don't know" answers than the others. I have decided to include it anyway because the rest of the data looks good.  

```{r lm-basic}
lm_basic <- lm(data = agg_data2022, 
               energy_int ~ percentage_Eólica + logEolica )
```

### Picking the right predictors: 

```{r fortune, results='hide'}
library(caret)
set.seed(124)
ctrl <- trainControl(method = "repeatedcv", 
                     number = 10, repeats = 10)

for_tune <- train(energy_int ~ logEolica + issues_p + 
                    mas + menos + ns + igual + 
                    land_area + logPopden + logGenTotal + 
                    percentage_Eólica + logPop + prec + tmin + tmax, 
                  data = agg_data2022, 
                  method = "leapForward", 
                  preProc = c('scale', 'center'),
                  tuneGrid = expand.grid(nvmax = 2:11),
                  trControl = ctrl)
```

```{r lm}
# for_tune
plot(for_tune, metric = "Rsquared")
coef(for_tune$finalModel, 3)
coef(for_tune$finalModel, 6)

lm_small <- lm(data = agg_data2022, 
        energy_int ~ logEolica + logGenTotal + logPop  )
lm_large <- lm(data = agg_data2022, 
      energy_int ~ logEolica  + mas + logPopden + logGenTotal + logPop + prec  ) 
```

### Is `month` a significant predictor?  

`aov_month` \
I ran several ANOVA models to test if month has a strong relationship with energy intensity, using wind energy and CCAA as covariates. \
_Null Hypothesis:_ There is no difference in mean energy intensity across months. \
_Alternate Hypothesis:_ At least one month has a mean significantly different from the others.

$$
H_0: \mu_{Jan} = \mu_{Feb} = \mu_{Mar} =  ...  = \mu_{Dec} 
$$

For the first ANOVA model, I only included `month`, which did not return statistically significant results. Here we cannot reject the null hypothesis that different months have different mean energy intensity across Spain. 

The second ANOVA model includes logged wind energy generated as a covariate and an interaction term with `month`. The `logEolica` covariate is significant (`p-value < 2e-16`) but neither of the terms with month are significant. This means that given the wind energy generated, the different months do not have a statistically significant effect on energy intensity. 

The third ANOVA model includes autonomous community `CCAAnombre` 


```{r aov, fig.height=4}
aov_0 <- aov(data = agg_data2022, 
             energy_int ~ month) 
aov_1 <- aov(data = agg_data2022, 
             energy_int ~ month*logEolica)
aov_2 <- aov(data = agg_data2022, 
             energy_int ~ month* percentage_Eólica  ) 
aov_3 <- aov(data = agg_data2022, 
             energy_int ~ month + CCAAnombre) 

agg_data2022 |> 
  ggplot(aes(y = energy_int, x = logEolica, color = month)) + 
  geom_line(alpha = .1) + geom_point(alpha = .1)+ 
  geom_smooth(method = "glm", se = T) +
  labs(
    title = "Mean energy intensity not significantly different across months"
  ) + new_theme

```

### CCAA is a significant predictors

Although CCAA seems to be a better predictor than month, the best model includes `month + CCAAnombre`. Having CCAA by itself won't do as well as including month, but it is still very good, as you can see in the RSS value compared to the other models. 

```{r}
aov_ccaa <- aov(data = agg_data2022, 
             energy_int ~ CCAAnombre)

anova(aov_0, aov_1, aov_2, aov_3, aov_ccaa)
```

### Mixed models with CCAA as Random Effect 

`lmer_basic`\
The first model 

```{r lmer}
library(lme4)

lmer_basic <- lmer(data = agg_data2022, 
      energy_int ~  logEolica + percentage_Eólica + 
      (1 | CCAAnombre) + (1 | month) ) 

lmer_large <- lmer(data = agg_data2022,
      energy_int ~ logEolica + mas + logPopden + logGenTotal + logPop + prec +
      ( logEolica | CCAAnombre)  + (1 | month) 
      )

lmer_large2 <- lmer(data = agg_data2022,
      energy_int ~ logEolica + mas + logPopden + logGenTotal + logPop + prec +
      ( 1 | CCAAnombre)  + (1 | month) 
      )
```


```{r}
names <- c("lm basic", "small", "large", "basic", "large")
stargazer::stargazer(lm_basic, lm_small, lm_large, lmer_basic, lmer_large, type = "text",
                     column.labels = names
                      )

modelsummary::modelsummary(list(lm_basic, lm_small, lm_large, lmer_basic, lmer_large), 
                           stars = T, 
                           output = "lm-models.png", 
                           statistic = NULL
                )

modelsummary::modelsummary(list(lmer_basic, lmer_large, lmer_large2), 
                           stars = T, 
                           output = "lmer-models.png", 
                           statistic = NULL
                )
```

## Test on past years

We will use 2014 data at the test data. 

```{r agg-2014}
agg_data2014 <- agg_data |> 
  filter(
    lubridate::year(date) == 2014
  ) 
```

```{r test-results}
test_results <- data.frame(actual_2014 = agg_data2014$energy_int)

test_results$lm_basic <- predict(lm_basic, agg_data2014)
test_results$lm_small <- predict(lm_small, agg_data2014)
test_results$lm_large <- predict(lm_large, agg_data2014)
test_results$lmer_basic <- lme4:::predict.merMod(lmer_basic, newdata = agg_data2014, se.fit = F)
test_results$lmer_large <- lme4:::predict.merMod(lmer_large, newdata = agg_data2014, se.fit = F)
```


## quick Notes

1.  The model (based on 2023 data) is way underestimating **Asturias**'s energy intensity values from 2014.
2.  Also **Cantabria** and **Galicia** but not as much.
3.  **Valencia** and **Andalucia** is about right.
4.  **La Rioja** is overestimated
5.  There's more overestimating than underestimating.


## Random forest

I decided to run a few _Random Forest_ models to get an unsupervised non-linear perspective. The linear models are great for interpretation, but are limited by the assumptions of regression. Random Forest models are not limited by the assumptions of fitting least squares of residuals. 

First thing I found was that **Asturias** is a clear outlier in the data and the random forest model picked it out easily. Look at the partial dependence plot with CCAA along the X-axis. The only CCAA that is significantly different from the rest is Asturias. The other CCAA and the most months are not important in this model.

```{r rf-tune}
library(caret)
library(pdp)
rf_tune <- train(
  energy_int ~ logEolica + issues_p + ns + mas + igual + 
  menos + logPop + prec + tmax + tmin + tmed + 
  logGenTotal + logPopden + month + CCAAnombre + land_area + percentage_Eólica , 
                 data = agg_data2022,
                 method = "rf",
                 preProc=c('scale','center'),
                 trControl = ctrl,
                 ntree = 100,
                 tuneGrid = data.frame(mtry=c(3,5,7,9,11,13)),
                 importance = TRUE)
plot(rf_tune)
```

```{r }
plot(varImp(rf_tune, scale = F) , scales = list(y = list(cex = .45)))

partial(rf_tune, pred.var = "logEolica", plot = T, rug = TRUE)
partial(rf_tune, pred.var = "prec", plot = T, rug = TRUE)
partial(rf_tune, pred.var = "logPopden", plot = T, rug = TRUE)
partial(rf_tune, pred.var = "CCAAnombre", plot = T, rug = TRUE)
```

```{r}
test_results$rf <- predict(rf_tune, agg_data2014)
```


According to random forest, which gets really good R^2^ and RMSE when testing against 2014 data, the month variable is not important. Most important is whether or not the CCAA is **Asturias**. Then the next top predictors are survey results, electricity generated and population density.

```{r asturias, eval=FALSE}
agg_data2014 |> 
  mutate(rf_predict = test_results$rf,
         rf_delta = rf_predict - energy_int
     ) |> 
  ggplot(aes(x = rf_delta, y = CCAAnombre)) + geom_point()+
  geom_vline(xintercept = 0) +
  labs(
    y = NULL,
    title = "Asturias and Galicia way underestimated on RF model",
    subtitle = "Estimate minus Actual Energy Intensiy"
  ) 
```

## RF without CCAA

I decided to run a _Random Forest_ model without a variable for CCAA. This removal should show us which variables are important to predict energy intensity, without directly asking, "Which autonomous community is this?" Although one possibility would be only keep the binary dummy variable for when CCAA is equal to Asturias. 

I also removed `month` because it has not shown to be important without CCAA involved. 

This shrunken model with fewer explanatory variables had somewhat similar results. The most important variable was if the CCAA was Asturias. That was such a big outlier I had to keep it as a binary variable. The other most important variables were average temperature and the survey results for `igual`. 

```{r}
rf_tune_noCCAA <- train(
  energy_int ~ logEolica + issues_p + ns + mas + menos + igual + 
  logGenTotal + logPopden + land_area + percentage_Eólica  +
  I(CCAAnombre == "Asturias") + prec + tmax + tmin + tmed, 
                 data = agg_data2022,
                 method = "rf",
                 preProc=c('scale','center'),
                 trControl = ctrl,
                 ntree = 100,
                 tuneGrid = data.frame(mtry=c(3,5,7,9,11)),
                 importance = TRUE)

plot(rf_tune_noCCAA)
```

```{r , fig.cap="Random forest without CCAA and Month"}
plot(varImp(rf_tune_noCCAA, scale = F) , scales = list(y = list(cex = .75)))

partial(rf_tune_noCCAA, pred.var = "logEolica", plot = T, rug = TRUE)
partial(rf_tune_noCCAA, pred.var = "prec", plot = T, rug = TRUE)
partial(rf_tune_noCCAA, pred.var = "menos", plot = T, rug = TRUE)
partial(rf_tune_noCCAA, pred.var = "percentage_Eólica", plot = T, rug = TRUE )
```


```{r}
test_results$rf_noCCAA <- predict(rf_tune_noCCAA, agg_data2014)

print("random forest w/out CCAA stats:")
postResample(pred = test_results$rf_noCCAA, obs = test_results$actual_2014)
```

## RF with small list of variables

```{r}
rf_tune_small <- train(
  energy_int ~ Eolica + prec + tmin + mas + issues_p + pop + 
    percentage_Eólica + GenTotal, 
                 data = agg_data2022,
                 method = "rf",
                 preProc=c('scale','center'),
                 trControl = ctrl,
                 ntree = 100,
                 tuneGrid = data.frame(mtry=c(2,3,4)),
                 importance = TRUE)

plot(rf_tune_small)
```

```{r , fig.cap="Random forest with small list of variables"}
plot(varImp(rf_tune_small, scale = F) , scales = list(y = list(cex = .95)))

partial(rf_tune_small, pred.var = "Eolica", plot = T, rug = TRUE)
partial(rf_tune_small, pred.var = "GenTotal", plot = T, rug = TRUE)
partial(rf_tune_small, pred.var = "percentage_Eólica", plot = T, rug = TRUE)
partial(rf_tune_small, pred.var = "issues_p", plot = T, rug = TRUE)
```

```{r}
test_results$rf_small <- predict(rf_tune_small, agg_data2014)


print("random forest w/small list of vars:")
postResample(pred = test_results$rf_small, obs = test_results$actual_2014)
```


## Regularized regression

**ElasticNet with CCAA :**

Regularized regression methods are good for reducing the strength of explanatory variables that are highly correlated with other variables. Many explanatory variables in the model are collinear, like the cliamte data and the survey data. 

Based off what we know from the previous analyzes, we can predict that CCAA will be a very important variable, even if it is used to detect **Asturias**. 

```{r glmnet-tune}
elastic_grid = expand.grid(alpha = seq(0, .2, 0.01), lambda = seq(0, .1, 0.01))
ctrl <- trainControl(method = "repeatedcv", 
                     number = 10, repeats = 10)

glmnet_tune <- train(data = agg_data2022,
  energy_int ~ logEolica + issues_p + logPop + 
  ns + mas + menos + igual + prec + I(prec^2) +
  logGenTotal + logPopden + month + 
  I(CCAAnombre == "Asturias") + land_area + percentage_Eólica,
                     method='glmnet',
                     preProc=c('scale','center'),
                     tuneGrid = elastic_grid,
                     trControl=ctrl
                 )
```

```{r glmnet_test}
plot(glmnet_tune)
glmnet_tune$bestTune

test_results$glmnet <- predict(glmnet_tune, agg_data2014)

postResample(pred = test_results$glmnet,  obs = test_results$actual_2014)
```

```{r}
plot(varImp(glmnet_tune, scale = F),
     scales = list(y = list(cex = .55))) 


partial(glmnet_tune, pred.var = "logEolica", plot = T, rug = TRUE) 
partial(glmnet_tune, pred.var = "logPopden", plot = T, rug = TRUE) 
partial(glmnet_tune, pred.var = "prec", plot = T, rug = TRUE) 
partial(glmnet_tune, pred.var = "CCAAnombre", plot = T, rug = TRUE) 

```

The elastic net model does a lot better than the other linear models based off R^2^.

**ElasticNet: without CCAA**

```{r}
glmnet_tune_noCCAA <- train(
  energy_int ~ logEolica + issues_p + ns + mas + menos + igual  + logPop + 
  logGenTotal + logPopden + prec + I(prec^2) + tmax + land_area + percentage_Eólica , 
  data = agg_data2022,
                     method='glmnet',
                     preProc=c('scale','center'),
                     tuneGrid = elastic_grid,
                     trControl=ctrl
                 )

plot(glmnet_tune_noCCAA)
glmnet_tune_noCCAA$bestTune

test_results$glmnet_noCCAA <- predict(glmnet_tune_noCCAA, agg_data2014)

postResample(pred = test_results$glmnet_noCCAA,  obs = test_results$actual_2014)
```

```{r}
plot(varImp(glmnet_tune_noCCAA, scale = F), scales = list(y = list(cex = .65))) 

partial(glmnet_tune_noCCAA, pred.var = "logEolica", plot = T, rug = TRUE) 
partial(glmnet_tune_noCCAA, pred.var = "logPopden", plot = T, rug = TRUE) 
partial(glmnet_tune_noCCAA, pred.var = "percentage_Eólica", plot = T, rug = TRUE) 
partial(glmnet_tune_noCCAA, pred.var = "prec", plot = T, rug = TRUE)
```

#### Interpretations without CCAA

Now we can see how much the differences between CCAA effect the energy intensity in ways I have not already included in the data. First of all, the R^2^ is a lot lower, but that is expected. 

 - The most important variables now are logged population density and logged wind energy generated. 
 - Land area and logged total electricity generated are considered somewhat important
 
Interesting that without the CCAA variable, the most important predictors change. This tells me that differences across regions make a huge difference. One important difference is climate and geography. Other factors could include investment in modern technology. 


## Comparing test results 

```{r}
colnames = colnames(test_results)
stats_results <- list()
for (i in 1:length(test_results)) {
  result <- postResample(pred = test_results[i], obs = test_results$actual_2014)
  n = colnames[i]
 # result["model"] = n
  stats_results[[n]] <-  result[1:3]
}
stats_results <- as.data.frame(t(as.data.frame(stats_results)))
stats_results$model = row.names(stats_results)
```

```{r}
stats_results |> 
  mutate(Rsq  = paste0(round(100*Rsquared, 1), "%") ) |> 
  ggplot(aes(xmax = Rsquared, xmin = 0,
             x = Rsquared, y = model, label = Rsq)) +
  geom_linerange() +
  geom_point() +
  geom_text(nudge_x = .05) +
  geom_vline(xintercept = 0) +
  labs(
    y = NULL, 
    subtitle = "Different models compared"
  ) +
  scale_x_continuous(
    labels = scales::label_percent(),
    breaks = c(0,.2,.4, .6, .8, 1)
  ) 
```


The ordinary linear regression models perform the worst. They are worse than the RF without CCAA. I think this is because RF uses non-linear techniques of manipulating the predictors and find the results in ways that linear regression cannot. Also, removing CCAA from the equation has a big factor in linear techniques. 

```{r , fig.height=7}

ggcorrplot::ggcorrplot(cor(test_results), type = "lower", 
                       ggtheme = new_theme, hc.order = F, lab = T,
                       
                       )

DataExplorer::plot_prcomp(test_results,  ggtheme = theme_classic(), )
DataExplorer::plot_density(test_results, 
                           title = "`rf`, `rf_noCCAA` and `lmer_basic` most closely resemble the actual 2014 energy intensity values", 
                           theme_config = list(panel.border = element_rect(colour = "black", fill = NA)
                                               )
                           )


```

```{r knn ,eval=FALSE}
knn_tune <- train(energy_int ~ logEolica + issues_p + ns + mas + igual + 
  menos + logPop + prec + tmax + tmin + tmed + 
  logGenTotal + logPopden + month + CCAAnombre + land_area + percentage_Eólica , 
                  data = agg_data2022,
                  method = "kknn",   
                  preProc=c('scale','center'), 
                  tuneGrid = data.frame(kmax=c(5,7,9,11,13,15), distance=2, kernel='optimal'),
                  trControl = ctrl)
plot(knn_tune)

knn_tune$bestTune

test_results$knn <- predict(knn_tune, agg_data2014)
```

```{r, eval=FALSE}
plot(varImp(knn_tune, scale = F) , scales = list(y = list(cex = .45)))
partial(knn_tune, pred.var = "CCAAnombre", plot = T)

postResample(pred = test_results$knn,  obs = test_results$actual_2014)
```


